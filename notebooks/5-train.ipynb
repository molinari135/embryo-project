{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d3894b",
   "metadata": {},
   "source": [
    "# Train, test and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbaa71cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-11 15:27:28.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36membryo_project.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: C:\\Users\\Molinari\\Desktop\\embryo-project\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os, torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR\n",
    "from torchvision import transforms\n",
    "from torchvision.models import vit_b_16  # ViT base, 16x16 patches\n",
    "from collections import Counter\n",
    "from loguru import logger\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "from embryo_project.config import PROCESSED_DATA_DIR, MODELS_DIR, REPORTS_DIR, FIGURES_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2df94d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-11 15:27:28.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m2\u001b[0m - \u001b[1mUsing device: cuda\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63c0b449",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbryoSequenceDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, max_seq_len=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.folders = sorted([f for f in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, f))])\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.folders)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        folder = self.folders[idx]\n",
    "        folder_path = os.path.join(self.root_dir, folder)\n",
    "\n",
    "        image_files = sorted(\n",
    "            [f for f in os.listdir(folder_path) if f.endswith('.JPG')],\n",
    "            key=lambda x: int(x.split('_')[-1].split('.')[0])  # extract index\n",
    "        )\n",
    "\n",
    "        images = []\n",
    "        for img_file in image_files:\n",
    "            img_path = os.path.join(folder_path, img_file)\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            images.append(img)\n",
    "\n",
    "        if self.max_seq_len:\n",
    "            images = images[:self.max_seq_len]\n",
    "            while len(images) < self.max_seq_len:\n",
    "                images.append(torch.zeros_like(images[0]))  # zero padding\n",
    "\n",
    "        images_tensor = torch.stack(images)  # [#images, #channels, heigth, weigth]\n",
    "\n",
    "        # 1 if any image has \"_1.JPG\", else 0\n",
    "        label = 1 if any(f.endswith('_1.JPG') for f in image_files) else 0\n",
    "\n",
    "        return images_tensor, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe8f39bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "MAX_SEQ_LEN = 20 # all 20 images\n",
    "# MAX_SEQ_LEN = 10 # only 10 images\n",
    "\n",
    "train_dataset = EmbryoSequenceDataset(PROCESSED_DATA_DIR / \"train\", transform=transform, max_seq_len=MAX_SEQ_LEN)\n",
    "val_dataset = EmbryoSequenceDataset(PROCESSED_DATA_DIR / \"val\", transform=transform, max_seq_len=MAX_SEQ_LEN)\n",
    "test_dataset = EmbryoSequenceDataset(PROCESSED_DATA_DIR / \"test\", transform=transform, max_seq_len=MAX_SEQ_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d088567d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18LSTM(nn.Module):\n",
    "    def __init__(self, cnn_embed_dim=512, lstm_hidden_size=128, num_layers=1, bidirectional=True):\n",
    "        super(ResNet18LSTM, self).__init__()\n",
    "\n",
    "        # resnet18\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        modules = list(resnet.children())[:-1]  # remove final\n",
    "        self.cnn = nn.Sequential(*modules)\n",
    "        self.cnn_embed_dim = cnn_embed_dim  # 512 for resnet18\n",
    "\n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=cnn_embed_dim,\n",
    "            hidden_size=lstm_hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "\n",
    "        # binary classification\n",
    "        direction_factor = 2 if bidirectional else 1\n",
    "        self.classifier = nn.Linear(lstm_hidden_size * direction_factor, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # B = number of folders inside the batch\n",
    "        # T = number of images in the folder\n",
    "        # C = number of image channels\n",
    "        # H = image height\n",
    "        # W = image width\n",
    "        B, T, C, H, W = x.size()\n",
    "\n",
    "        x = x.view(B * T, C, H, W)\n",
    "        cnn_feats = self.cnn(x).view(B, T, -1)  # [B*T, 512] -> [B, T, 512]\n",
    "\n",
    "        lstm_out, _ = self.lstm(cnn_feats)  # [B, T, H]\n",
    "        last_output = lstm_out[:, -1, :]    # last time step [B, H]\n",
    "\n",
    "        logits = self.classifier(last_output)  # [B, 1]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "433de7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim=256, lstm_layers=1, dropout=0.1):\n",
    "        super(ViTLSTM, self).__init__()\n",
    "        # Load pretrained ViT backbone without classification head\n",
    "        self.vit = vit_b_16(pretrained=True)\n",
    "        self.vit.heads = nn.Identity()  # remove ViT classifier head\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=768,  # ViT base embedding size\n",
    "                            hidden_size=hidden_dim,\n",
    "                            num_layers=lstm_layers,\n",
    "                            batch_first=True,\n",
    "                            dropout=dropout if lstm_layers > 1 else 0)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [B, T, C, H, W] (sequence of images)\n",
    "        B, T, C, H, W = x.shape\n",
    "        x = x.view(B * T, C, H, W)  # flatten batch and time for ViT input\n",
    "        vit_feats = self.vit(x)       # [B*T, 768]\n",
    "        vit_feats = vit_feats.view(B, T, -1)  # reshape to sequence: [B, T, 768]\n",
    "\n",
    "        lstm_out, _ = self.lstm(vit_feats)  # [B, T, hidden_dim]\n",
    "        last_hidden = lstm_out[:, -1, :]    # take last time step [B, hidden_dim]\n",
    "\n",
    "        out = self.classifier(last_hidden)  # [B, 1]\n",
    "        return out.squeeze(1)  # [B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8367b924",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple3DCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Simple3DCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool3d(2)\n",
    "        self.conv2 = nn.Conv3d(16, 32, 3, padding=1)\n",
    "        self.pool2 = nn.MaxPool3d(2)\n",
    "        self.conv3 = nn.Conv3d(32, 64, 3, padding=1)\n",
    "        self.pool3 = nn.AdaptiveAvgPool3d(1)  # Output size = (batch, 64, 1, 1, 1)\n",
    "        self.fc = nn.Linear(64, 1)  # Binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))  # [B,16,T/1,H/1,W/1]\n",
    "        x = self.pool1(x)          # Downsample\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)          # [B,64,1,1,1]\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc(x)             # [B,1]\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2546d670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=10,\n",
    "    patience=5,\n",
    "    best_model_path=\"best_model.pth\",\n",
    "    scheduler=None,\n",
    "    use_early_stopping=True,\n",
    "    is_vit=False,\n",
    "    is_cnn=False\n",
    "):\n",
    "    best_val_f1 = 0.0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # --- Training ---\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        all_preds_train, all_labels_train = [], []\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            if is_cnn:\n",
    "                inputs = inputs.permute(0, 2, 1, 3, 4).to(device)\n",
    "            else:\n",
    "                inputs = inputs.to(device)\n",
    "            labels = labels.float().to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            if is_vit:\n",
    "                outputs = model(inputs)\n",
    "            else:\n",
    "                outputs = model(inputs).squeeze(1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).int()\n",
    "            all_preds_train.extend(preds.cpu().numpy())\n",
    "            all_labels_train.extend(labels.cpu().numpy())\n",
    "\n",
    "        train_acc = accuracy_score(all_labels_train, all_preds_train)\n",
    "        train_f1 = f1_score(all_labels_train, all_preds_train)\n",
    "\n",
    "        # --- Validation ---\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        all_preds_val, all_labels_val = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                if is_cnn:\n",
    "                    inputs = inputs.permute(0, 2, 1, 3, 4).to(device)\n",
    "                else:\n",
    "                    inputs = inputs.to(device)\n",
    "                labels = labels.float().to(device)\n",
    "\n",
    "                if is_vit:\n",
    "                    outputs = model(inputs)\n",
    "                else:\n",
    "                    outputs = model(inputs).squeeze(1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_losses.append(loss.item())\n",
    "\n",
    "                preds = (torch.sigmoid(outputs) > 0.5).int()\n",
    "                all_preds_val.extend(preds.cpu().numpy())\n",
    "                all_labels_val.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_acc = accuracy_score(all_labels_val, all_preds_val)\n",
    "        val_f1 = f1_score(all_labels_val, all_preds_val)\n",
    "\n",
    "        logger.info(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        logger.info(f\"  Train Loss: {sum(train_losses)/len(train_losses):.4f} | Acc: {train_acc:.4f} | F1: {train_f1:.4f}\")\n",
    "        logger.info(f\"  Val   Loss: {sum(val_losses)/len(val_losses):.4f} | Acc: {val_acc:.4f} | F1: {val_f1:.4f}\")\n",
    "\n",
    "        # Scheduler step (if provided)\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()  \n",
    "\n",
    "        # --- Early Stopping ---\n",
    "        if use_early_stopping:\n",
    "            if val_f1 > best_val_f1:\n",
    "                best_val_f1 = val_f1\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "                logger.success(f\"New best model saved at {best_model_path} with F1: {best_val_f1:.4f}\")\n",
    "                epochs_no_improve = 0\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                if epochs_no_improve >= patience:\n",
    "                    logger.warning(\"Early stopping triggered\")\n",
    "                    break\n",
    "        else:\n",
    "            # Always save best model regardless of patience\n",
    "            if val_f1 > best_val_f1:\n",
    "                best_val_f1 = val_f1\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "                logger.success(f\"New best model saved at {best_model_path} with F1: {best_val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a19917db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_save_results(\n",
    "        model,\n",
    "        test_loader,\n",
    "        device,\n",
    "        model_name, \n",
    "        models_dir=MODELS_DIR,\n",
    "        reports_dir=REPORTS_DIR,\n",
    "        figures_dir=FIGURES_DIR,\n",
    "        is_cnn=False\n",
    "    ):\n",
    "    \n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    os.makedirs(reports_dir, exist_ok=True)\n",
    "    os.makedirs(figures_dir, exist_ok=True)\n",
    "\n",
    "    best_model_path = os.path.join(models_dir, f\"{model_name}.pth\")\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    model.eval()\n",
    "\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            if is_cnn:\n",
    "                inputs = inputs.permute(0, 2, 1, 3, 4).to(device)\n",
    "            else:\n",
    "                inputs = inputs.to(device)\n",
    "            labels = labels.float().to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).int()\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # classification report\n",
    "    report = classification_report(all_labels, all_preds, \n",
    "                                    target_names=[\"Class 0\", \"Class 1\"], digits=4)\n",
    "    report_path = os.path.join(reports_dir, f\"{model_name}_report.txt\")\n",
    "    with open(report_path, \"w\") as f:\n",
    "        f.write(report)\n",
    "    logger.success(f\"Classification report saved to {report_path}\")\n",
    "\n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Class 0\", \"Class 1\"])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    disp.plot(ax=ax, cmap=plt.cm.Blues, values_format='d')\n",
    "    plt.title(f\"Confusion Matrix - {model_name}\")\n",
    "    cm_path = os.path.join(figures_dir, f\"{model_name}_cm.png\")\n",
    "    plt.savefig(cm_path)\n",
    "    plt.close()\n",
    "    logger.success(f\"Confusion matrix saved to {cm_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c88f263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class distribution for weigths\n",
    "labels = [label for _, label in train_dataset]\n",
    "label_counts = Counter(labels)\n",
    "\n",
    "neg = label_counts[0]\n",
    "pos = label_counts[1]\n",
    "pos_weight = torch.tensor([neg / pos]).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a2c71c",
   "metadata": {},
   "source": [
    "## ResNet18 + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3d056e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Molinari\\Desktop\\embryo-project\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Molinari\\Desktop\\embryo-project\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model_name = \"ResNet18LSTM\"\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "best_model_path = MODELS_DIR / f\"{model_name}.pth\"\n",
    "\n",
    "resnet18 = ResNet18LSTM().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = optim.AdamW(resnet18.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "num_epochs = 10\n",
    "patience = 5\n",
    "best_f1 = 0.0\n",
    "epochs_no_improve = 0\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "# scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "825fd7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-11 15:28:43.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mEpoch 1/10\u001b[0m\n",
      "\u001b[32m2025-08-11 15:28:43.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1m  Train Loss: 1.2855 | Acc: 0.6866 | F1: 0.1569\u001b[0m\n",
      "\u001b[32m2025-08-11 15:28:43.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1m  Val   Loss: 1.1656 | Acc: 0.7619 | F1: 0.2222\u001b[0m\n",
      "\u001b[32m2025-08-11 15:28:43.880\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m89\u001b[0m - \u001b[32m\u001b[1mNew best model saved at C:\\Users\\Molinari\\Desktop\\embryo-project\\models\\ResNet18LSTM.pth with F1: 0.2222\u001b[0m\n",
      "\u001b[32m2025-08-11 15:29:32.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mEpoch 2/10\u001b[0m\n",
      "\u001b[32m2025-08-11 15:29:32.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1m  Train Loss: 0.8417 | Acc: 0.8367 | F1: 0.3333\u001b[0m\n",
      "\u001b[32m2025-08-11 15:29:32.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1m  Val   Loss: 1.1835 | Acc: 0.6871 | F1: 0.2069\u001b[0m\n",
      "\u001b[32m2025-08-11 15:30:18.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mEpoch 3/10\u001b[0m\n",
      "\u001b[32m2025-08-11 15:30:18.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1m  Train Loss: 0.6285 | Acc: 0.8047 | F1: 0.3558\u001b[0m\n",
      "\u001b[32m2025-08-11 15:30:18.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1m  Val   Loss: 2.0569 | Acc: 0.9048 | F1: 0.2222\u001b[0m\n",
      "\u001b[32m2025-08-11 15:31:03.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mEpoch 4/10\u001b[0m\n",
      "\u001b[32m2025-08-11 15:31:03.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1m  Train Loss: 0.5270 | Acc: 0.8936 | F1: 0.4966\u001b[0m\n",
      "\u001b[32m2025-08-11 15:31:03.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1m  Val   Loss: 1.9536 | Acc: 0.8707 | F1: 0.2963\u001b[0m\n",
      "\u001b[32m2025-08-11 15:31:03.586\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m89\u001b[0m - \u001b[32m\u001b[1mNew best model saved at C:\\Users\\Molinari\\Desktop\\embryo-project\\models\\ResNet18LSTM.pth with F1: 0.2963\u001b[0m\n",
      "\u001b[32m2025-08-11 15:31:48.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mEpoch 5/10\u001b[0m\n",
      "\u001b[32m2025-08-11 15:31:48.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1m  Train Loss: 0.4566 | Acc: 0.8921 | F1: 0.5000\u001b[0m\n",
      "\u001b[32m2025-08-11 15:31:48.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1m  Val   Loss: 1.8751 | Acc: 0.8571 | F1: 0.2759\u001b[0m\n",
      "\u001b[32m2025-08-11 15:32:33.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mEpoch 6/10\u001b[0m\n",
      "\u001b[32m2025-08-11 15:32:33.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1m  Train Loss: 0.2389 | Acc: 0.9461 | F1: 0.6838\u001b[0m\n",
      "\u001b[32m2025-08-11 15:32:33.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1m  Val   Loss: 1.9045 | Acc: 0.8571 | F1: 0.2759\u001b[0m\n",
      "\u001b[32m2025-08-11 15:33:17.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mEpoch 7/10\u001b[0m\n",
      "\u001b[32m2025-08-11 15:33:17.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1m  Train Loss: 0.2045 | Acc: 0.9577 | F1: 0.7339\u001b[0m\n",
      "\u001b[32m2025-08-11 15:33:17.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1m  Val   Loss: 1.9437 | Acc: 0.8571 | F1: 0.2759\u001b[0m\n",
      "\u001b[32m2025-08-11 15:34:02.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mEpoch 8/10\u001b[0m\n",
      "\u001b[32m2025-08-11 15:34:02.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1m  Train Loss: 0.1795 | Acc: 0.9708 | F1: 0.8000\u001b[0m\n",
      "\u001b[32m2025-08-11 15:34:02.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1m  Val   Loss: 2.1047 | Acc: 0.8639 | F1: 0.2308\u001b[0m\n",
      "\u001b[32m2025-08-11 15:34:46.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mEpoch 9/10\u001b[0m\n",
      "\u001b[32m2025-08-11 15:34:46.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1m  Train Loss: 0.1761 | Acc: 0.9752 | F1: 0.8247\u001b[0m\n",
      "\u001b[32m2025-08-11 15:34:46.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1m  Val   Loss: 2.3904 | Acc: 0.8707 | F1: 0.2400\u001b[0m\n",
      "\u001b[32m2025-08-11 15:34:46.833\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m94\u001b[0m - \u001b[33m\u001b[1mEarly stopping triggered\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    resnet18,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    patience,\n",
    "    best_model_path,\n",
    "    scheduler,\n",
    "    use_early_stopping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58da522c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-11 15:34:54.460\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate_and_save_results\u001b[0m:\u001b[36m40\u001b[0m - \u001b[32m\u001b[1mClassification report saved to C:\\Users\\Molinari\\Desktop\\embryo-project\\reports\\ResNet18LSTM_report.txt\u001b[0m\n",
      "\u001b[32m2025-08-11 15:34:54.514\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate_and_save_results\u001b[0m:\u001b[36m52\u001b[0m - \u001b[32m\u001b[1mConfusion matrix saved to C:\\Users\\Molinari\\Desktop\\embryo-project\\reports\\figures\\ResNet18LSTM_cm.png\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "evaluate_and_save_results(\n",
    "    resnet18,\n",
    "    test_loader,\n",
    "    device,\n",
    "    model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c586922d",
   "metadata": {},
   "source": [
    "## ViT + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "313c4768",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Molinari\\Desktop\\embryo-project\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Molinari\\Desktop\\embryo-project\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model_name = \"ViTLSTM\"\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "best_model_path = MODELS_DIR / f\"{model_name}.pth\"\n",
    "\n",
    "vitlstm = ViTLSTM(hidden_dim=256, lstm_layers=1, dropout=0.1).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = optim.AdamW(vitlstm.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "num_epochs = 10\n",
    "patience = 5\n",
    "best_f1 = 0.0\n",
    "epochs_no_improve = 0\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "# scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef115eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-11 15:43:12.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mEpoch 1/10\u001b[0m\n",
      "\u001b[32m2025-08-11 15:43:12.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1m  Train Loss: 1.3818 | Acc: 0.5991 | F1: 0.0924\u001b[0m\n",
      "\u001b[32m2025-08-11 15:43:12.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1m  Val   Loss: 1.4288 | Acc: 0.0612 | F1: 0.1154\u001b[0m\n",
      "\u001b[32m2025-08-11 15:43:12.990\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m89\u001b[0m - \u001b[32m\u001b[1mNew best model saved at C:\\Users\\Molinari\\Desktop\\embryo-project\\models\\ViTLSTM.pth with F1: 0.1154\u001b[0m\n",
      "\u001b[32m2025-08-11 15:50:53.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mEpoch 2/10\u001b[0m\n",
      "\u001b[32m2025-08-11 15:50:53.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1m  Train Loss: 1.3538 | Acc: 0.5481 | F1: 0.0988\u001b[0m\n",
      "\u001b[32m2025-08-11 15:50:53.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1m  Val   Loss: 1.3873 | Acc: 0.7551 | F1: 0.0526\u001b[0m\n",
      "\u001b[32m2025-08-11 15:58:32.913\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mEpoch 3/10\u001b[0m\n",
      "\u001b[32m2025-08-11 15:58:32.913\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1m  Train Loss: 1.3236 | Acc: 0.3542 | F1: 0.0978\u001b[0m\n",
      "\u001b[32m2025-08-11 15:58:32.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1m  Val   Loss: 1.3418 | Acc: 0.7551 | F1: 0.0526\u001b[0m\n",
      "\u001b[32m2025-08-11 16:06:07.882\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mEpoch 4/10\u001b[0m\n",
      "\u001b[32m2025-08-11 16:06:07.882\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1m  Train Loss: 1.3109 | Acc: 0.7522 | F1: 0.1414\u001b[0m\n",
      "\u001b[32m2025-08-11 16:06:07.882\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1m  Val   Loss: 1.4068 | Acc: 0.0612 | F1: 0.1154\u001b[0m\n",
      "\u001b[32m2025-08-11 16:13:44.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mEpoch 5/10\u001b[0m\n",
      "\u001b[32m2025-08-11 16:13:44.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1m  Train Loss: 1.3332 | Acc: 0.3120 | F1: 0.1094\u001b[0m\n",
      "\u001b[32m2025-08-11 16:13:44.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1m  Val   Loss: 1.3306 | Acc: 0.0612 | F1: 0.1154\u001b[0m\n",
      "\u001b[32m2025-08-11 16:21:22.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mEpoch 6/10\u001b[0m\n",
      "\u001b[32m2025-08-11 16:21:22.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1m  Train Loss: 1.3060 | Acc: 0.4723 | F1: 0.1084\u001b[0m\n",
      "\u001b[32m2025-08-11 16:21:22.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1m  Val   Loss: 1.3315 | Acc: 0.0612 | F1: 0.1154\u001b[0m\n",
      "\u001b[32m2025-08-11 16:21:22.023\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m94\u001b[0m - \u001b[33m\u001b[1mEarly stopping triggered\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    vitlstm,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    patience,\n",
    "    best_model_path,\n",
    "    scheduler,\n",
    "    use_early_stopping=True,\n",
    "    is_vit=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f07db6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-11 16:26:09.981\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate_and_save_results\u001b[0m:\u001b[36m40\u001b[0m - \u001b[32m\u001b[1mClassification report saved to C:\\Users\\Molinari\\Desktop\\embryo-project\\reports\\ViTLSTM_report.txt\u001b[0m\n",
      "\u001b[32m2025-08-11 16:26:10.044\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate_and_save_results\u001b[0m:\u001b[36m52\u001b[0m - \u001b[32m\u001b[1mConfusion matrix saved to C:\\Users\\Molinari\\Desktop\\embryo-project\\reports\\figures\\ViTLSTM_cm.png\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Molinari\\Desktop\\embryo-project\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Molinari\\Desktop\\embryo-project\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Molinari\\Desktop\\embryo-project\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "evaluate_and_save_results(\n",
    "    vitlstm,\n",
    "    test_loader,\n",
    "    device,\n",
    "    model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a16d2ad",
   "metadata": {},
   "source": [
    "## 3DCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4e1ff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"3DCNN\"\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "best_model_path = MODELS_DIR / f\"{model_name}.pth\"\n",
    "\n",
    "cnn = Simple3DCNN().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = optim.AdamW(cnn.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "num_epochs = 10\n",
    "patience = 5\n",
    "best_f1 = 0.0\n",
    "epochs_no_improve = 0\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "# scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1994b4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-11 16:27:09.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mEpoch 1/10\u001b[0m\n",
      "\u001b[32m2025-08-11 16:27:09.561\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1m  Train Loss: 1.3123 | Acc: 0.1283 | F1: 0.0912\u001b[0m\n",
      "\u001b[32m2025-08-11 16:27:09.561\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1m  Val   Loss: 1.3315 | Acc: 0.3197 | F1: 0.1228\u001b[0m\n",
      "\u001b[32m2025-08-11 16:27:09.564\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m89\u001b[0m - \u001b[32m\u001b[1mNew best model saved at C:\\Users\\Molinari\\Desktop\\embryo-project\\models\\3DCNN.pth with F1: 0.1228\u001b[0m\n",
      "\u001b[32m2025-08-11 16:27:55.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mEpoch 2/10\u001b[0m\n",
      "\u001b[32m2025-08-11 16:27:55.752\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1m  Train Loss: 1.3044 | Acc: 0.6516 | F1: 0.1115\u001b[0m\n",
      "\u001b[32m2025-08-11 16:27:55.752\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1m  Val   Loss: 1.3298 | Acc: 0.0816 | F1: 0.1176\u001b[0m\n",
      "\u001b[32m2025-08-11 16:28:41.786\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mEpoch 3/10\u001b[0m\n",
      "\u001b[32m2025-08-11 16:28:41.787\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1m  Train Loss: 1.3035 | Acc: 0.5860 | F1: 0.1180\u001b[0m\n",
      "\u001b[32m2025-08-11 16:28:41.787\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1m  Val   Loss: 1.3242 | Acc: 0.0612 | F1: 0.1154\u001b[0m\n",
      "\u001b[32m2025-08-11 16:29:27.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mEpoch 4/10\u001b[0m\n",
      "\u001b[32m2025-08-11 16:29:27.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1m  Train Loss: 1.2919 | Acc: 0.1064 | F1: 0.1129\u001b[0m\n",
      "\u001b[32m2025-08-11 16:29:27.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1m  Val   Loss: 1.3146 | Acc: 0.1633 | F1: 0.1277\u001b[0m\n",
      "\u001b[32m2025-08-11 16:29:27.724\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m89\u001b[0m - \u001b[32m\u001b[1mNew best model saved at C:\\Users\\Molinari\\Desktop\\embryo-project\\models\\3DCNN.pth with F1: 0.1277\u001b[0m\n",
      "\u001b[32m2025-08-11 16:30:14.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mEpoch 5/10\u001b[0m\n",
      "\u001b[32m2025-08-11 16:30:14.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1m  Train Loss: 1.2808 | Acc: 0.4985 | F1: 0.1400\u001b[0m\n",
      "\u001b[32m2025-08-11 16:30:14.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1m  Val   Loss: 1.2985 | Acc: 0.3605 | F1: 0.1607\u001b[0m\n",
      "\u001b[32m2025-08-11 16:30:14.198\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m89\u001b[0m - \u001b[32m\u001b[1mNew best model saved at C:\\Users\\Molinari\\Desktop\\embryo-project\\models\\3DCNN.pth with F1: 0.1607\u001b[0m\n",
      "\u001b[32m2025-08-11 16:30:57.575\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mEpoch 6/10\u001b[0m\n",
      "\u001b[32m2025-08-11 16:30:57.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1m  Train Loss: 1.2512 | Acc: 0.2318 | F1: 0.1318\u001b[0m\n",
      "\u001b[32m2025-08-11 16:30:57.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1m  Val   Loss: 1.2948 | Acc: 0.4422 | F1: 0.1800\u001b[0m\n",
      "\u001b[32m2025-08-11 16:30:57.578\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m89\u001b[0m - \u001b[32m\u001b[1mNew best model saved at C:\\Users\\Molinari\\Desktop\\embryo-project\\models\\3DCNN.pth with F1: 0.1800\u001b[0m\n",
      "\u001b[32m2025-08-11 16:31:40.469\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mEpoch 7/10\u001b[0m\n",
      "\u001b[32m2025-08-11 16:31:40.469\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1m  Train Loss: 1.2457 | Acc: 0.5875 | F1: 0.2117\u001b[0m\n",
      "\u001b[32m2025-08-11 16:31:40.469\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1m  Val   Loss: 1.2923 | Acc: 0.6871 | F1: 0.2581\u001b[0m\n",
      "\u001b[32m2025-08-11 16:31:40.473\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m89\u001b[0m - \u001b[32m\u001b[1mNew best model saved at C:\\Users\\Molinari\\Desktop\\embryo-project\\models\\3DCNN.pth with F1: 0.2581\u001b[0m\n",
      "\u001b[32m2025-08-11 16:32:25.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mEpoch 8/10\u001b[0m\n",
      "\u001b[32m2025-08-11 16:32:25.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1m  Train Loss: 1.2520 | Acc: 0.7055 | F1: 0.2231\u001b[0m\n",
      "\u001b[32m2025-08-11 16:32:25.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1m  Val   Loss: 1.2892 | Acc: 0.7075 | F1: 0.2456\u001b[0m\n",
      "\u001b[32m2025-08-11 16:33:12.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mEpoch 9/10\u001b[0m\n",
      "\u001b[32m2025-08-11 16:33:12.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1m  Train Loss: 1.2357 | Acc: 0.7012 | F1: 0.2379\u001b[0m\n",
      "\u001b[32m2025-08-11 16:33:12.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1m  Val   Loss: 1.2861 | Acc: 0.7551 | F1: 0.2174\u001b[0m\n",
      "\u001b[32m2025-08-11 16:33:58.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mEpoch 10/10\u001b[0m\n",
      "\u001b[32m2025-08-11 16:33:58.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1m  Train Loss: 1.2307 | Acc: 0.6195 | F1: 0.2209\u001b[0m\n",
      "\u001b[32m2025-08-11 16:33:58.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_model\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1m  Val   Loss: 1.2831 | Acc: 0.7483 | F1: 0.1778\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    cnn,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    patience,\n",
    "    best_model_path,\n",
    "    scheduler,\n",
    "    use_early_stopping=True,\n",
    "    is_cnn=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbe61392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-11 16:34:05.502\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate_and_save_results\u001b[0m:\u001b[36m40\u001b[0m - \u001b[32m\u001b[1mClassification report saved to C:\\Users\\Molinari\\Desktop\\embryo-project\\reports\\3DCNN_report.txt\u001b[0m\n",
      "\u001b[32m2025-08-11 16:34:05.545\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mevaluate_and_save_results\u001b[0m:\u001b[36m52\u001b[0m - \u001b[32m\u001b[1mConfusion matrix saved to C:\\Users\\Molinari\\Desktop\\embryo-project\\reports\\figures\\3DCNN_cm.png\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "evaluate_and_save_results(\n",
    "    cnn,\n",
    "    test_loader,\n",
    "    device,\n",
    "    model_name,\n",
    "    is_cnn=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
